# Introducción a Big Data
 
  Este es mi primera investigacion en el curso de Big Data
  
  ## Installation
   
  Algunas de las herramientas de la investigacion
   
  | tecnologia | Link                                                     |        ¿Quien?                                            | ¿Para qué sirve?|
  | :---:          | :---:                                                        | :---:                                                                                     | :---: |
  | Docker                | [docker](https://docker.com)  |       Solomon Hykes                                                               |  para instanciar nuevos proyectos  |
  | MapReduce                | [MapReduce](https://MapReduce.com)  |       Doug Cutting                                                               |  MapReduce es un modelo de programación para dar soporte a la computación paralela sobre grandes colecciones de datos en grupos de computadoras y al commodity computing.   |
  |haddop| [hadoop](https://hadoop.com)|Doug Cutting  | Apache Hadoop es un framework de software que soporta aplicaciones distribuidas bajo una licencia libre. Permite a las aplicaciones trabajar con miles de nodos y petabytes de datos. Hadoop se inspiró en los documentos Google para MapReduce y Google File System (GFS).	|
  | Spark                | [Spark](https://apachespark.com)  |       Apache                                                               |  Apache Spark es un sistema de computación que se basa en Hadoop Map Reduce y que, principalmente, permite dividir o paralelizar el trabajo, ya que normalmente se instala en un clúster de máquina.   |
  | Flume                | [Spark](https://apacheflume.com)  |       Apache                                                               |  Flume es un servicio distribuido que mueve de forma fiable y eficiente grandes cantidades de datos, especialmente logs. Ideal para aplicaciones de analíticas en línea en entornos Hadoop.   |
